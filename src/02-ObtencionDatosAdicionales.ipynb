{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb397646-4ae7-4bbf-89d2-b2b95e0ed9e8",
   "metadata": {},
   "source": [
    "<img src=\"images/header.png\" alt=\"Logo UCLM-ESII\" align=\"right\">\n",
    "\n",
    "<br><br><br><br>\n",
    "<h2><font color=\"#92002A\" size=4>Trabajo Fin de Máster</font></h2>\n",
    "\n",
    "<h1><font color=\"#6B001F\" size=5>SERENDIPITY: Servicio web para la recomendacIón de playlists a partir de otra playlist</font></h1>\n",
    "<h2><font color=\"#92002A\" size=3>Parte 2 - Obtención de datos adicionales</font></h2>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "    <font color=\"#B20033\" size=3><strong>Autor</strong>: <em>Miguel Ángel Cantero Víllora</em></font><br>\n",
    "    <br>\n",
    "    <font color=\"#B20033\" size=3><strong>Directores</strong>: <em>José Antonio Gámez Martín</em></font><br>\n",
    "    <font color=\"#B20033\" size=3><em>Juan Ángel Aledo Sánchez</em></font><br>\n",
    "    <br>\n",
    "<font color=\"#B20033\" size=3>Máster Universitario en Ingeniería Informática</font><br>\n",
    "<font color=\"#B20033\" size=2>Escuela Superior de Ingeniería Informática | Universidad de Castilla-La Mancha</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8775c-b6ca-44d6-aae9-e998bc6f2cb8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#92002A\" size=5>Índice</font></h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Creación de etiquetas](#section2)\n",
    "    * [2.1. - Construcción de la matriz TF-IDF](#section21)\n",
    "* [3. Obtención de géneros musicales (artistas)](#section3)\n",
    "* [4. Obtención de fechas de lanzamiento (álbumes)](#section4)\n",
    "* [5. Obtención de características músicales (pistas)](#section5)\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8927b65b-edea-4067-88be-84cb7d6e9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from modules import emojis\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94865782-0dc7-4bf8-8b12-bc50a7e8c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPD_CSV_PATH = 'MPD_CSV'\n",
    "TFIDF_DATA_FILE = os.path.join(MPD_CSV_PATH,'mpd.tfidf-data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9c453-a38d-4c14-afcf-8e1df9fb02ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "## <font color=\"#92002A\">1 - Introducción</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3670fda-788a-482c-8b96-58559d173f67",
   "metadata": {},
   "source": [
    "Con el fin de obtener mejores predicciones, vamos a obtener información adicional sobre las pistas que conforman una playlist empleando [*Spotipy*](https://spotipy.readthedocs.io) para acceder a la [API de *Spotify*](https://developer.spotify.com/documentation/web-api/). Mediante uso de técnicas de *Procesamiento del Lenguaje Natural* o *NLP* (*Natural Language Processing*), también vamos a procesar los títulos de las playlist para convertirlos en etiquetas o *tokens*, con lo cual conseguiremos relacionar playlists de títulos similares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ab17a4-d01e-49af-b0ac-838e6a92e971",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7910a096-0d83-41cf-b1f4-1890ff63aa3e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section2\"></a>\n",
    "## <font color=\"#92002A\">2 - Creación de etiquetas</font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7952fe-eb0d-4fa0-96b7-88d90e0b8529",
   "metadata": {},
   "source": [
    "Para la creación de etiquetas, con las que identificaremos las playlists y nos ayudaran a relacionarlas con otras similares, partiremos de los títulos y los procesaremos de tal manera que queden en un formato común (todos los caracteres en minúscula, sin signos de puntuación, ...). También identificaremos aquellas playlists cuyo nombre contiene algún emoticono y transformarlo a texto, todo ello obteniendo los términos más frecuentes que aparecen junto a cada emoticono.\n",
    "\n",
    "<br>\n",
    "\n",
    "Primero, creamos un *dataframe* en el que almacenaremos los títulos de las playlist, y los *emojis* que contiene cada playlist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a471f7dd-08ce-4d24-bb47-b2d28086951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = pd.read_csv('MPD_CSV/mpd.playlists-info.csv')['name'].to_frame()\n",
    "df_names = pd.concat([df_names, pd.read_csv('MPD_CSV/mpd.playlists-info-test.csv', index_col=0)['name'].to_frame()])\n",
    "\n",
    "df_names['name'] = df_names['name'].astype(str)\n",
    "df_names.index.name = \"pl_pid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2853e1fb-4fc7-4fe5-bce2-32233b49dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names['emojis'] = df_names['name'].apply(emojis.get_emojis_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac9fa26-caf6-4028-bd2c-b34e537d2212",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Una vez que se ha creado el *dataframe* con los títulos de las playlists y los emojis que posee, vamos a crear una serie de funciones con las que eliminaremos del texto aquellos elementos que no deseamos:\n",
    "\n",
    "* `replace_apostrophe`: Se encarga de transformar algunos casos particulares donde el apóstrofe aparece en el título.\n",
    "* `dot_remover`: Elimina el punto de los títulos y cuando una palabra está separada por puntos (por ejemplo: H.A.P.P.Y. o 1.9.9.9.), elimina dichos puntos y junta los caracteres para formar la palabra. Como excepción si el título contiene un número, lo mantendremos.\n",
    "* `clean_name`: Función que se encarga de eliminar caracteres no deseados y transformar el texto para que todos los títulos tengan un formato común."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "904bc6f5-d53d-4c24-8adb-f295b841c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_apostrophe(text):\n",
    "    # Como caso excepcional, vamos a hacer que el género R'n'B  se conserve como\n",
    "    # una única palabra, rnb.\n",
    "    if text.lower() == \"r'n'b\":\n",
    "        return \"rnb\"\n",
    "    \n",
    "    # Adaptamos décadas como 1990's ó 90's para que aparezcan como\n",
    "    # 1990s ó 90s.\n",
    "    text = re.sub(r\"([0-9]+)'s\", r'\\1s', text)\n",
    "    text = text.replace(\"'s \", \" \")\n",
    "    \n",
    "    text = re.sub(r\"([0-9]+)´s\", r'\\1s', text)\n",
    "    text = text.replace(\"´s \", \" \")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84b588e1-b50e-4d4a-852c-d96d98537492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_remover(text):\n",
    "    # Si el texto contiene un punto, realiza la comprobación.\n",
    "    if \".\" in text:\n",
    "        d = dict()\n",
    "        \n",
    "        for token in word_tokenize(text):\n",
    "            cond_1 = \".\" in token\n",
    "            cond_2 = len(token) > 2\n",
    "            cond_3 = token.count('.') >= int(len(token)/2)\n",
    "            cond_4 = not(token.count('.') == 1 and token.replace(\".\",\"\").isnumeric())\n",
    "            # Comprobamos si la palabra es separada por puntos.\n",
    "            if all([cond_1, cond_2, cond_3, cond_4]):\n",
    "                d[token] = token.replace('.','')\n",
    "            else:\n",
    "                # Comprobamos si la palabra del texto es un número.\n",
    "                result = re.match(r\"^[0-9]+([,.][0-9]+)?$\", token)\n",
    "                if result != None:\n",
    "                    d[result.string] = result.string.replace(\",\",\"{dot}\").replace(\".\",\"{dot}\")\n",
    "\n",
    "        for k,v in d.items():\n",
    "            text = text.replace(k,v)\n",
    "        \n",
    "        text = text.replace(\".\",\" \")\n",
    "        text = text.replace(\"{dot}\",\".\")\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebef253e-f85e-4577-b490-64e522edc4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    name = str(name).lower() # Convierte todo a minúscula.\n",
    "    name = replace_apostrophe(name)\n",
    "    name = dot_remover(name)\n",
    "    name = re.sub(r\"[~_]\", ' ', name) # Elimina los caracteres '~' y '_'.\n",
    "    name = re.sub(r\"[^\\w\\s\\.]\", ' ', name) # Elimina signos de puntuación.\n",
    "    \n",
    "    tokens = list()\n",
    "    for token in word_tokenize(name):\n",
    "        token = emojis.remove_emojis(token) # Elimina emojis.\n",
    "        token = re.sub(r'\\s+', ' ', token).strip() # Elimina espacios en blanco consecutivos.\n",
    "        tokens.append(token)\n",
    "        \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f496b-a804-4432-8cc0-29843ecdae29",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Tras definir las funciones, procedemos a crear una nueva columumna en `df_names` con el título procesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6cb7720-ac7d-41b8-9ad1-1f49d8ab4f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 1010000/1010000 [01:44<00:00, 9663.26it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "df_names['tags'] = df_names['name'].progress_apply(clean_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c6ffd6-dfce-442b-81a4-6498cc59acee",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Como último paso, vamos a crear un diccionario con el que realizaremos los cambios de emojis por las palabras con las que aparece con mayor frecuencia. Para ello, nos apoyaremos en la función `create_emojis_dict`, la cual se encargará de crearlo y nos dará opción de coger las *n* primeras palabras que aparecen con mayor frecuencia. También tendremos la opción de excluir determinadas palabras que consideremos que no aportan demasiada información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6117713-73bb-401e-81d7-48dcfa7892be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emojis_dict(df, removable_words=[], num_tags=5):\n",
    "    emojis_set = set()\n",
    "    emoji_dict = dict()\n",
    "    \n",
    "    for emoji_title in df[df['emojis'] != '']['emojis'].to_list(): \n",
    "        emojis_set.update(emoji_title)\n",
    "        \n",
    "    df_titles_emojis = df[df['emojis'] != '']\n",
    "\n",
    "    for emoji_char in emojis_set:\n",
    "        tags = \" \".join(df_titles_emojis[df_titles_emojis['emojis'].str.contains(emoji_char)]['tags'].to_list())\n",
    "        tags_list = [tag for tag in tags.split(' ') if len(tag) > 0]\n",
    "        words_count_dict = defaultdict(int)\n",
    "\n",
    "        for tag in tags_list:\n",
    "            words_count_dict[tag] += 1\n",
    "\n",
    "        words_count_dict = dict(sorted(words_count_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "        result = [k for k,v in words_count_dict.items() \n",
    "                  if k not in removable_words and\n",
    "                  not(k.isnumeric())][:num_tags]\n",
    "        if len(result) > 0:\n",
    "            emoji_dict[emoji_char] = result\n",
    "            \n",
    "    return emoji_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "489d6a7a-f96b-4716-bf92-ca0339e1aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis_dict = create_emojis_dict(df_names, removable_words= [\"music\", \"playlist\", \"song\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e12949a-73eb-41c6-b657-79826b5c80e6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Llegados a este punto, ya podemos crear el conjunto de etiquetas o *tokens* que contiene cada playlist de nuestro conjunto.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5bc35-d632-42ca-a9f7-80f48e73020a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section21\"></a>\n",
    "### <font color=\"#92002A\">2.1 - Construcción de la matriz TF-IDF</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "Para poder entrenar nuestro modelo de recomendación a partir de un conjunto de documentos de texto, en nuestro caso los títulos de las playlists, es necesario representar estos datos en una matriz bidimensional. En el modelo _Bag of Words_, cada documento se representa a partir del conjunto de palabras que aparecen en él. Como paso previo a la construcción de la matriz de datos, se elabora un vocabulario con la unión de todos los términos que aparecen en algún documento. A partir de éste, se construye una matriz en la que cada fila representa un documento, y cada columna (cada característica) corresponde a un término. \n",
    "\n",
    "En la versión más básica, cada posición ${(d,t)}$ de la matriz contiene el valor para la medida ___Term Frequency___ (frecuencia de términos), que se denota *tf*$_{d,t}$, y refleja al número de veces que aparece el término $t$ en el documento $d$. Por ejemplo, dados estos tres documentos:\n",
    "\n",
    "* Documento 1: \"El objetivo de esta práctica es explicar el procesamiento básico de texto libre\",\n",
    "* Documento 2: \"Uno de los enfoques utilizados es la bolsa de palabras\",\n",
    "* Documento 3: \"Procesamiento de texto mediante bolsa de palabras\",\n",
    "\n",
    "la medida _Term Frequency_  generaría esta matriz de datos:\n",
    "\n",
    "<br>\n",
    "$$\n",
    "X = \\left[ \\begin{array}{c | c | c | c | c | c | c }\n",
    "El  & objetivo & de & esta & \\cdots & bolsa & palabras \\\\\n",
    "2 & 1 & 2 & 1 & \\cdots & 0 & 0\\\\\n",
    "0 & 0 & 2 & 0 & \\cdots & 1 & 1\\\\\n",
    "0 & 0 & 2 & 0 & \\cdots & 1 & 1\\\\\n",
    "\\end{array}  \\right] \\begin{array}{c}\n",
    "\\\\\n",
    "Documento \\, 1 \\\\\n",
    "Documento \\, 2 \\\\\n",
    "Documento \\, 3 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "En la matriz, *tf*$_{0,1}=2$, porque la palabra de índice $0$, \"El\", aparece dos veces en el documento $1$. \n",
    "\n",
    "Existen algunas variantes de esta medida, de modo que la matriz de datos se puede formar con:\n",
    "\n",
    "* *tf*$_{d,t} \\in \\{0,1\\}$ - Es decir, si el término aparece o no en el documento.\n",
    "* $\\lg(1+tf_{d,t})$ - Escala logarítmica.\n",
    "* *tf*$_{d,t}/max_j$ *tf*$_{d,j}$ - Escala en relación al término más frecuente en el documento.\n",
    "<br>\n",
    "\n",
    "\n",
    "La frecuencia de términos comunes como \"el\", \"a\", \"de\", etc, suele ser alta para la mayoría de los documentos. La métrica ___Inverse Document Frequency___ (frecuencia inversa en documentos) penaliza los términos en proporción a la frecuencia con que aparecen en el conjunto de documentos. La frequencia inversa de un término se formula como:\n",
    "\n",
    "$$\n",
    "idf_t = log\\left(\\frac{\\# \\,documentos}{\\# \\,documentos \\, que \\, incluyen \\, la \\, palabra \\, t }\\right)\n",
    "$$\n",
    "\n",
    "En el ejemplo anterior:\n",
    "\n",
    "* $ idf_{el} = log\\left(\\frac{3}{1}\\right) = 1.098 $\n",
    "* $idf_{objetivo} = log\\left(\\frac{3}{1}\\right) = 1.098$\n",
    "* $idf_{de} = log\\left(\\frac{3}{3}\\right) = 0$\n",
    "* $idf_{esta} = log\\left(\\frac{3}{1}\\right) = 1.098$\n",
    "* $idf_{bolsa} = log\\left(\\frac{3}{2}\\right) = 0.405$\n",
    "* $idf_{palabras} = log\\left(\\frac{3}{2}\\right) = 0.405$\n",
    "\n",
    "<br>\n",
    "Existen algunas formulaciones alternativas como:\n",
    "\n",
    "$$\n",
    "idf_t = log\\left(\\frac{1 + \\# \\,documentos}{1 + \\# \\,documentos \\, que \\, incluyen \\, la \\, palabra \\, t }\\right) + 1\n",
    "$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Por último, lo habitual es utilizar una combinación de estas métricas, denominada ___Term Frequency Inverse Document Frequency (tf-idf)___ , que se formula como:\n",
    "\n",
    "$$\n",
    "tf-idf_{d,t} = tf_{d,t} \\times idf_t\n",
    "$$\n",
    "<br>\n",
    "\n",
    "Dados los documentos anteriores, la matriz con los valores *tf-idf*$_{d,t}$ sería:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "X = \\left[ \\begin{array}{c | c | c | c | c | c | c }\n",
    "El  & objetivo & de & esta & \\cdots & bolsa & palabras \\\\\n",
    "2.2 & 1.1 & 2.2 & 1.1 & \\cdots & 0 & 0\\\\\n",
    "0 & 0 & 2.2 & 0 & \\cdots & 0.81 & 0.81\\\\\n",
    "0 & 0 & 2.2 & 0 & \\cdots & 0.81 & 0.81\\\\\n",
    "\\end{array}  \\right] \\begin{array}{c}\n",
    "\\\\\n",
    "Documento \\, 1 \\\\\n",
    "Documento \\, 2 \\\\\n",
    "Documento \\, 3 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c212f-5289-4358-b711-6a813f05b5a3",
   "metadata": {},
   "source": [
    "Para crear la matriz *tf-idf*, vamos a emplear la clase [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Dicha función forma parte del módulo de [extracción de características de texto](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text) de la librería [*scikit-learn*](https://scikit-learn.org/).\n",
    "\n",
    "Antes de crear dicha matriz, en vez de usar el *tokenizer* que emplea por defecto `TfidfVectorizer`, vamos a definir uno propio. Para ello, nos vamos a basar en la función `clean_name` que empleamos para *normalizar* los títulos de las playlist. Ésta nueva función, llamada `name_tokenizer`, va a realizar el mismo proceso que la anterior salvo por los siguientes cambios:\n",
    "* Sustituye los emojis del título por los dos primeros términos que se encuentran en el diccionario que hemos creado (`emojis_dict`). En caso de que el emoji no se encuentre en dicho diccionario, procederemos a incorporarlo al texto.\n",
    "* Retornara una lista de `strings` con los tokens obtenidos del título de la playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b1ae6b3-1749-47fe-b66a-84f291df7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_tokenizer(name):\n",
    "    emoji_list = emojis.get_emojis_list(name)\n",
    "    \n",
    "    name = str(name).lower()\n",
    "    name = replace_apostrophe(name)\n",
    "    name = dot_remover(name)\n",
    "    name = re.sub(r\"[~_]\", ' ', name)\n",
    "    name = re.sub(r\"[^\\w\\s\\.]\", ' ', name)\n",
    "    \n",
    "    tokens = list()\n",
    "    for token in word_tokenize(name):\n",
    "        token = emojis.remove_emojis(token)\n",
    "        token = re.sub(r'\\s+', ' ', token).strip()\n",
    "        tokens.append(token)\n",
    "    \n",
    "    emojis_translations = set()\n",
    "    for e in emoji_list:\n",
    "        if e in emojis_dict:\n",
    "            emojis_translations.update(emojis_dict[e][:2])\n",
    "        else:\n",
    "            emojis_translations.add(e)\n",
    "            \n",
    "    for t in emojis_translations:\n",
    "        if t not in tokens:\n",
    "            tokens.append(t)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c00974c9-a92d-4031-86fe-da69e38b8df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos una lista con los títulos de las playlists\n",
    "pls_names_list = df_names['name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51dca8ee-12f4-46d0-8cd5-97893f8b67ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Creamos la matriz tf_idf\\nX = vectorizer.fit_transform(pls_names_list)\\nprint(f\"Dimensiones: {X.shape}\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Definimos el vectorizador indicando que vamos a usar nuestro propio tokenizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=name_tokenizer)\n",
    "\"\"\"\n",
    "# Creamos la matriz tf_idf\n",
    "X = vectorizer.fit_transform(pls_names_list)\n",
    "print(f\"Dimensiones: {X.shape}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5248598-e0cb-4d38-80b9-f9b5f6329711",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Una vez creada la matriz, creamos un diccionario que contendrá:\n",
    "* El vectorizador creado\n",
    "* La lista que conforman las características obtenidas.\n",
    "* La matriz *tf-idf*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a338da7-fa94-4700-bb81-d6a37ce61f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntfidf_data_dict['vectorizer'] = vectorizer\\ntfidf_data_dict['features_list'] = vectorizer.get_feature_names()\\ntfidf_data_dict['matrix'] = X\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_data_dict = dict()\n",
    "\"\"\"\n",
    "tfidf_data_dict['vectorizer'] = vectorizer\n",
    "tfidf_data_dict['features_list'] = vectorizer.get_feature_names()\n",
    "tfidf_data_dict['matrix'] = X\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "007d860a-3299-4d14-988e-b423e6ce62c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Guardamos el diccionario creado en un fichero pickle\\nwith open(TFIDF_DATA_FILE, \"wb\") as write_file:\\n    pickle.dump(tfidf_data_dict, write_file, protocol=pickle.HIGHEST_PROTOCOL)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\"\"\"\n",
    "# Guardamos el diccionario creado en un fichero pickle\n",
    "with open(TFIDF_DATA_FILE, \"wb\") as write_file:\n",
    "    pickle.dump(tfidf_data_dict, write_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2823fa-1ecf-4493-85f1-9df2a784ec83",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672bf6db-64ab-42e9-a95e-b45fc23b733e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section3\"></a>\n",
    "## <font color=\"#92002A\">3 - Obtención de géneros musicales (artistas)</font>\n",
    "<br>\n",
    "\n",
    "En esta sección, vamos a obtener los géneros musicales de los artistas que conforman nuestro conjunto de datos (puesto que *Spotify* no proporciona los géneros para pistas y/o álbumes). Usaremos esta información para etiquetar las pistas que pertenezcan a un artista con los mismos géneros musicales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbe582-77c9-4202-9e9e-282c3478eeef",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Creamos el gestor de *Spotipy* con el cual obtendremos la información de *Spotify*, empleando los credenciales necesarios para acceder a la API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b526f2ff-86fc-418d-b86b-b9dae41abbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91c1c0b2-273e-4e8c-8e93-fe7f561c3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_client_id = '78007ce51a07476f8edc56984f02b9f3' #SpotifyClientID\n",
    "sp_client_secret = 'f7d87b63601946b1b1d0d5ff8b2524e0' #SpotifyClientSecret\n",
    "\n",
    "# Crea el gestor\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=sp_client_id, client_secret=sp_client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae929e1-6466-4a4f-8379-5e14614c60f7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Como en cada llamada a la API de *Spotify* sólo podemos obtener la información de 50 artistas, dividimos la lista que contiene los identificadores de los artistas en bloques de 50 identificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e503319-1e6f-4fff-9e90-3156e9a36472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9517e-154b-4cea-8136-54645da07b56",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Descargamos la información de los artistas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60376385-cdb1-48c2-b160-091c8bde89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con los identificadores de los artistas\n",
    "artists_ids = pd.read_csv('MPD_CSV/mpd.artists.csv', index_col=0)['artist_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ca5324a-a1df-4997-b4e8-47a40bd036ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "artist_chunks = get_list_chunks(artists_ids, 50)\n",
    "artists_results = []\n",
    "\n",
    "\"\"\"\n",
    "for chunk in tqdm(artist_chunks, total=len(artists_ids)/50):\n",
    "    results = sp.artists(chunk)['artists']\n",
    "    artists_results += [{'artist_id': d['id'], 'genres' : d['genres']} for d in results\n",
    "                        if d != None and 'genres' in d.keys()]\n",
    "    time.sleep(0.15)\n",
    "\"\"\"\n",
    "\n",
    "with open(\"backup/artists_genres.pkl\", \"rb\") as read_file:\n",
    "    artists_results = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd07cb-63cc-4cef-99c3-01327ca39001",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Una vez obtenida la información de los artistas, creamos un diccionario cuyos elementos tendran como clave el identificador del artista y como valor el conjunto de generos al que pertenece, separados por el caracter `|`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "026f857a-e2ed-4d86-ae55-940ca78d9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_genres_dict = dict()\n",
    "for artist in artists_results:\n",
    "    artist_genres_dict[artist['artist_id']] = \"|\".join(artist['genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f9af3-4728-4aaa-a309-cb7128c5b192",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Creamos un *dataframe* de *pandas* a partir del diccionario obtenido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2fad22d-650a-4bde-8e66-cb7104c59902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genres = pd.DataFrame.from_dict(artist_genres_dict, orient='index', columns=['genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a8cc3-6c8c-4ff6-9d02-5677a09fc99c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Nos quedamos con aquellos artistas de los cuales se disponga de información sobre sus generos y almacenmos la información en un fichero *CSV*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e478c9b-0eff-4520-b649-cc2bd0b2caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genres = df_genres[df_genres['genres'] != '']\n",
    "df_genres.to_csv('MPD_CSV/mpd.artists-genres.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae1937-fb40-45de-aa4b-7b09cdf0012b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e2e1b-1eeb-4e22-81c0-5d6308f493a0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section4\"></a>\n",
    "## <font color=\"#92002A\">4 - Obtención de fechas de lanzamiento (álbumes)</font>\n",
    "\n",
    "<br>\n",
    "\n",
    "Habitualmente, se suelen crear playlists que contienen pistas que pertenecen a un año, década o periodo de tiempo determinado, recopilando lo mejor de ese tiempo, canciones favoritas de una época, etc.\n",
    "\n",
    "Como *Spotify* proporciona la fecha de lanzamiento de los álbumes que posee, vamos a obtener dicha información para el conjunto de álbumes que componen nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73c31dbe-f932-4431-bcd6-2833297aa6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con los identificadores de los álbumes\n",
    "album_ids = pd.read_csv('MPD_CSV/mpd.albums.csv', index_col=0)['album_id'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173c9701-95dc-4083-b5e5-4469e95f5d96",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Al igual que sucede con los artistas, por cada llamada a la API de *Spotify*, sólo podemos obtener la información de 20 álbumes. Para ello volvemos a crear grupos de álbumes para realizar las llamadas a la API y obtener la fecha de lanzamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2fbddda-1a82-41a7-a49b-584daa0724d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "album_chunks = get_list_chunks(album_ids, 20)\n",
    "album_results = []\n",
    "\n",
    "\"\"\"\n",
    "for chunk in tqdm_nb(album_chunks, total=len(album_ids)/20):\n",
    "    results = sp.albums(chunk)['albums']\n",
    "    album_results += [{'id': d['album_id'], 'release_date' : d['release_date']} for d in results\n",
    "                      if d != None and 'release_date' in d.keys()]\n",
    "    time.sleep(0.15)\n",
    "\"\"\"\n",
    "\n",
    "with open(\"backup/albums_release.pkl\", \"rb\") as read_file:\n",
    "    album_results = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c7c2dd-a1ba-41ba-9285-6229316131fa",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Tras terminar de descargarse la información de los álbumes, creamos un *dataframe* de *pandas* a partir de la lista de diccionarios obtenida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3db405f-4226-4d24-8e85-75e96b27881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albums_release = pd.DataFrame(album_results)\n",
    "df_albums_release.set_index('album_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d422b6e-6bec-4145-a560-f578d5c67f70",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Eliminamos aquellos álbumes que no dispongan de fecha de lanzamiento, en el caso de existir, y guardamos la información en un fichero *CSV*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3e0e877-d1c5-48f3-b33d-e8c2b1e5ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albums_release = df_albums_release[df_albums_release['release_date'] != '']\n",
    "df_albums_release.to_csv('MPD_CSV/mpd.albums-releasedate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ae946-f0ea-4303-9032-2101a4c0a327",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a0f0f-9eb8-41fa-9750-68f225678020",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section5\"></a>\n",
    "## <font color=\"#92002A\">5 - Obtención de características músicales (pistas)</font>\n",
    "<br>\n",
    "\n",
    "Otro tipo de información que nos ofrece *Spotify*, y que puede resultarnos útil para crear nuestro modelo de recomendación, son las características de audio (o *audio features*) para las pistas, obtenidas tras realizar un análisis de audio de la canción. Las características disponibles son las siguientes:\n",
    "\n",
    "* **Capacidad de baile (*Danceability*)**: La capacidad de baile describe cómo de adecuada es una pista para bailar en función de una combinación de elementos musicales que incluyen el tempo, la estabilidad del ritmo, la fuerza del ritmo y la regularidad general. Un valor de 0.0 es menos bailable y 1.0 es el más bailable. \n",
    "\n",
    "* **Acústica (*Acousticness*)**: Valor comprendido entre 0.0 y 1.0 que indica el nivel de acústica de la pista. \n",
    "\n",
    "* **Energía (*Energy*)**: Valor comprendido entre 0.0 a 1.0 y que representa una medida de percepción de intensidad y actividad. Por lo general, las pistas enérgicas se sienten rápidas, de volumen alto y ruidosas. \n",
    "\n",
    "* **Instrumentalidad (Instrumentalness)**: Predice si una pista no contiene voces. Cuanto más cercano esté el valor de instrumentalidad a 1.0, mayor será la probabilidad de que la pista no contenga contenido vocal.\n",
    "\n",
    "* **Vivacidad (*Liveness*)**: Detecta la presencia de una audiencia en la grabación. Los valores de vivacidad más altos representan una mayor probabilidad de que la pista se haya interpretado en vivo.\n",
    "\n",
    "* **Sonoridad (*Loudness*)**: Indica la sonoridad general de una pista en decibelios (dB). Los valores de sonoridad se promedian en toda la pista. Los valores típicos oscilan entre -60 y 0 db.\n",
    "\n",
    "* **Habla (Speechiness)**: El habla detecta la presencia de palabras habladas en una pista. Cuanto más exclusivamente parecida a un discurso sea la grabación (por ejemplo, programa de entrevistas, audiolibro, poesía), más cercano a 1.0 será el valor del atributo.\n",
    "\n",
    "* **Tempo**: El tempo total estimado de una pista en pulsaciones por minuto (o *BPM*). En terminología musical, el tempo es la velocidad o el ritmo de una pieza determinada y se deriva directamente de la duración media del tiempo. \n",
    "\n",
    "* **Valencia (*Valence*)**: Medida entre 0.0 y 1.0 que describe la positividad musical que transmite una pista. Las pistas con valencia alta suenan más positivas (feliz, alegre, eufórico, ...), mientras que las pistas con valencia baja suenan más negativas (triste, deprimido, enojado, ...).\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "758f9971-322a-46fd-8ab2-6c54a305ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con los identificadores de las pistas\n",
    "track_ids = pd.read_csv('MPD_CSV/mpd.tracks.csv', index_col=0)['track_id'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe6552-13f3-4f95-ade7-ecd64a7a9a88",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Como ha sucedido en los casos anteriores, por cada llamada a la API de *Spotify*, sólo podemos obtener la información de 100 pistas. Para ello volvemos a crear grupos de pistas para realizar las llamadas a la API y obtener las características musicales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2fd22e1-cf18-4852-b884-913c1647a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_chunks = get_list_chunks(track_ids, 100)\n",
    "track_results = []\n",
    "\n",
    "\"\"\"\n",
    "for chunk in tqdm(track_chunks, total=len(track_ids)/100):\n",
    "    track_results += sp.audio_features(tracks=chunk)\n",
    "    time.sleep(0.15)\n",
    "\"\"\"\n",
    "\n",
    "with open(\"backup/audiofeats_full.pkl\", \"rb\") as read_file:\n",
    "    track_results = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca40223-ae16-4fa8-9bfa-346bdcacb735",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Una vez completada la descarga de las características musicales, cargamos la información obtenida en un *dataframe* de *pandas*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f340dd6f-7f2b-4aef-9242-facd708f370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audiofeats = pd.DataFrame(track_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c6d574-64d7-42ee-9ae2-590a2e51131a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Si estudiamos el contenido del *dataframe*, podemos ver que también se han obtenido algunos valores (como la url de la pista, duración, duración, ...) que no necesitamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84cc06e7-1f62-4baf-94a2-7b71f275728c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5048058 entries, 0 to 5048057\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   danceability      float64\n",
      " 1   energy            float64\n",
      " 2   key               int64  \n",
      " 3   loudness          float64\n",
      " 4   mode              int64  \n",
      " 5   speechiness       float64\n",
      " 6   acousticness      float64\n",
      " 7   instrumentalness  float64\n",
      " 8   liveness          float64\n",
      " 9   valence           float64\n",
      " 10  tempo             float64\n",
      " 11  type              object \n",
      " 12  id                object \n",
      " 13  uri               object \n",
      " 14  track_href        object \n",
      " 15  analysis_url      object \n",
      " 16  duration_ms       int64  \n",
      " 17  time_signature    int64  \n",
      "dtypes: float64(9), int64(4), object(5)\n",
      "memory usage: 693.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_audiofeats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e2f986-1c87-4ca3-8a1d-af6319360672",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Eliminamos dichos valores, establecemos el id de la pista como índice y lo guardamos en un fichero de formato *CSV*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b124709-6972-41e3-a6cd-8aeaeca69c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_audiofeats.drop(columns=['mode','type','uri','track_href','analysis_url','duration_ms','time_signature'], inplace=True)\n",
    "df_audiofeats.set_index('id', inplace=True)\n",
    "df_audiofeats.index.name = 'track_id'\n",
    "\n",
    "df_audiofeats.to_csv('MPD_CSV/mpd.tracks-audiofeats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971be95-8a0f-45c0-b418-db07a7a0fd9d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-graduation-cap\" aria-hidden=\"true\" style=\"color:#92002A\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
