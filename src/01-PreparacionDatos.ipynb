{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bba3559-4735-4b75-8be0-11a436770e58",
   "metadata": {},
   "source": [
    "<img src=\"images/header.png\" alt=\"Logo UCLM-ESII\" align=\"right\">\n",
    "\n",
    "<br><br><br><br>\n",
    "<h2><font color=\"#92002A\" size=4>Trabajo Fin de Máster</font></h2>\n",
    "\n",
    "<h1><font color=\"#6B001F\" size=5>SERENDIPITY: Servicio web para la recomendacIón de playlists a partir de otra playlist</font></h1>\n",
    "<h2><font color=\"#92002A\" size=3>Parte 1 - Preparación de datos</font></h2>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "    <font color=\"#B20033\" size=3><strong>Autor</strong>: <em>Miguel Ángel Cantero Víllora</em></font><br>\n",
    "    <br>\n",
    "    <font color=\"#B20033\" size=3><strong>Directores</strong>: <em>José Antonio Gámez Martín</em></font><br>\n",
    "    <font color=\"#B20033\" size=3><em>Juan Ángel Aledo Sánchez</em></font><br>\n",
    "    <br>\n",
    "<font color=\"#B20033\" size=3>Máster Universitario en Ingeniería Informática</font><br>\n",
    "<font color=\"#B20033\" size=2>Escuela Superior de Ingeniería Informática | Universidad de Castilla-La Mancha</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c7569-738d-49e9-92be-6cb9e4cde424",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#92002A\" size=5>Índice</font></h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Cambio de formato del dataset](#section2)\n",
    "* [3. Modificaciones adicionales en el dataset](#section3)\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3089c990-bceb-4403-8e71-d4402d36e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm as tqdm_nb\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e1d67d-1daa-4f09-8d08-c78aa5a545e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPD_PATH = 'MPD'\n",
    "MPD_TEST_PATH = 'MPD_TEST'\n",
    "MPD_CSV_PATH = 'MPD_CSV'\n",
    "MPD_SLICE_PREFIX = 'mpd.slice.'\n",
    "PLSTRS_PREFIX = 'mpd.playlists-tracks.'\n",
    "MPD_TEST_FILE = 'challenge_set.json'\n",
    "\n",
    "ALBUMS_FILE = os.path.join(MPD_CSV_PATH,'mpd.albums.csv')\n",
    "ARTISTS_FILE = os.path.join(MPD_CSV_PATH,'mpd.artists.csv')\n",
    "TRACKS_FILE = os.path.join(MPD_CSV_PATH,'mpd.tracks.csv')\n",
    "PLSTRS_FILE = os.path.join(MPD_CSV_PATH,'mpd.pls-tracks.csv')\n",
    "PLSTARTS_FILE = os.path.join(MPD_CSV_PATH,'mpd.pls-artists.csv')\n",
    "PLSALBUMS_FILE = os.path.join(MPD_CSV_PATH,'mpd.pls-albums.csv')\n",
    "PLSINFO_FILE = os.path.join(MPD_CSV_PATH,'mpd.playlists-info.csv')\n",
    "PLSTESTINFO_FILE = os.path.join(MPD_CSV_PATH,'mpd.playlists-info-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55a34b-4ffc-4034-b2e6-d7c217828130",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "## <font color=\"#92002A\">1 - Introducción</font>\n",
    "<br>\n",
    "\n",
    "En esta libreta, vamos a realizar una serie de cambios en el conjunto de playlists que obtuvimos en el proyecto _[Generación automática de playlist de canciones mediante técnicas de minería de datos](https://github.com/miguelangelcv/TFG-GeneracionPlaylists)_. Lo primero que haremos será convertirlos de su formato original, *json*, a formato *csv*. Este cambio lo realizamos para reducir su tamaño y poder almacenarlo en memoria y que también sea compatible con librerías como _[numpy](https://numpy.org/)_ o _[pandas](https://pandas.pydata.org/)_. También realizaremos una serie de modificaciones adicionales para eliminar información innecesaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90b262-14db-42e4-b23e-da8715d2d451",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3f4157-2be9-471c-ab7b-ef86d51d1a8a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section2\"></a>\n",
    "## <font color=\"#92002A\">2 - Cambio de formato del dataset</font>\n",
    "<br>\n",
    "\n",
    "\n",
    "Este proceso generará varios ficheros *csv* que contendrán distinta información, ya sea sobre las playlists, artistas, pistas, etc. Lo hacemos de dicha forma para que la información este mejor clasificada y sea más fácil trabajar con ella.\n",
    "\n",
    "Para realizar el cambio de formato del dataset, hemos creado una serie de funciones que nos ayudaran a leer y transformar los datos:\n",
    "\n",
    "* `json_file_reader`: Esta función permite leer los ficheros que componen el conjunto de datos, ya sea un archivo *json* o un archivo *zip* que lo contenga.\n",
    "* `jsonds_to_csvds`: Se encarga procesar todos los ficheros correspondientes al conjunto de datos que contiene las playlists y transformarlos a formato *csv* y repartir la información en varios ficheros. \n",
    "* `jsonds_to_csvds_test`: Realiza el mismo proceso que la función anterior, pero con el conjunto de datos que emplearemos como conjunto de prueba (o test).\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a243cb9d-2ee0-439a-8556-6716588c3264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función que nos permite leer un archivo .json comprimido o sin comprimir\n",
    "# y devuelve un diccionario con su contenido\n",
    "def json_file_reader(file_path):\n",
    "    \"\"\"\n",
    "    :param file_path: Ruta del fichero a leer.\n",
    "    :return results: Diccionario con los datos leidos del fichero JSON.\n",
    "    \"\"\"\n",
    "    _ , file_extension = os.path.splitext(file_path)\n",
    "\n",
    "    # Fichero comprimido\n",
    "    if file_extension == '.zip':\n",
    "        with ZipFile(file_path,'r') as zip_file:\n",
    "            with zip_file.open(zip_file.namelist()[0]) as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "    # Fichero sin comprimir\n",
    "    elif file_extension == '.json':\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            json_data = json.load(json_file)            \n",
    "    # En caso de que sea otra extensión, devolvemos un diccionario vacío\n",
    "    else:\n",
    "        json_data = {}            \n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ddcec2e-0438-483e-8dc4-b475dd8a01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que se encarga de convertir el dataset que contiene \n",
    "# 1 millón de playlists a formato CSV\n",
    "def jsonds_to_csvds(json_ds_path,csv_ds_path):\n",
    "    \"\"\"\n",
    "    :param json_ds_path: Ruta donde se encuentra el conjunto de datos en formato JSON.\n",
    "    :param csv_ds_path: Ruta donde almacenaremos el nuevo conjunto de datos en formato CSV.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(csv_ds_path):\n",
    "        os.mkdir(csv_ds_path)    \n",
    "    \n",
    "    files = []\n",
    "    tracks_dict = defaultdict(dict)\n",
    "\n",
    "    for file in os.listdir(json_ds_path):\n",
    "        if file.startswith(MPD_SLICE_PREFIX):\n",
    "            files.append(os.path.join(json_ds_path,file))\n",
    "\n",
    "    plstrs_fieldnames = ['pid','pos','track_uri']\n",
    "    tracks_fieldnames = ['track_name', 'track_uri', 'duration_ms', 'artist_name', \n",
    "                         'artist_uri', 'album_name', 'album_uri']\n",
    "    plsinfo_fieldnames = ['pid','name','collaborative','modified_at',\n",
    "                          'num_albums','num_tracks', 'num_followers',\n",
    "                          'num_edits','duration_ms','num_artists','description']\n",
    "\n",
    "    with open(PLSINFO_FILE,'w',newline='') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=plsinfo_fieldnames,delimiter=',')\n",
    "        writer.writeheader()\n",
    "\n",
    "    print(\"[1/2] Lectura de datos en JSON:\")\n",
    "    for file in tqdm_nb(files):\n",
    "        file_name , _ = os.path.splitext(file)\n",
    "        portion = file_name.split('.')[-1]\n",
    "        csv_pltrs_file = os.path.join(csv_ds_path, f\"{PLSTRS_PREFIX}{portion}.csv\")\n",
    "        row_list = []\n",
    "\n",
    "        with open(PLSINFO_FILE,'a',encoding='utf8',newline='') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=plsinfo_fieldnames,\n",
    "                                    delimiter=',',quoting=csv.QUOTE_MINIMAL)\n",
    "            for pl in json_file_reader(file)['playlists']:\n",
    "                tracks_list = pl.pop('tracks')\n",
    "                writer.writerow(pl)\n",
    "                for track in tracks_list:\n",
    "                    pos = track.pop('pos')\n",
    "                    row = {'pid': pl['pid'], 'pos': pos,\n",
    "                           'track_uri' : track['track_uri']}\n",
    "                    row_list.append(row)\n",
    "                    tracks_dict[track['track_uri']] = track\n",
    "\n",
    "        with open(csv_pltrs_file,'w',newline='') as csv_tracks_file:\n",
    "            writer_tracks = csv.DictWriter(csv_tracks_file, fieldnames=plstrs_fieldnames)\n",
    "            writer_tracks.writeheader()\n",
    "            for row in row_list:\n",
    "                writer_tracks.writerow(row)\n",
    "    \n",
    "    print(\"[2/2] Almacenamiento de datos en CSV:\")\n",
    "    with open(TRACKS_FILE,'w',newline='', encoding='utf8') as csv_tracks_file:\n",
    "        writer_tracks = csv.DictWriter(csv_tracks_file, fieldnames=tracks_fieldnames)\n",
    "        writer_tracks.writeheader()\n",
    "        pbar = tqdm_nb(total=len(tracks_dict))\n",
    "        for track in tracks_dict.values():\n",
    "            writer_tracks.writerow(track)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da276de7-5a64-4a2c-907e-b4841140ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que se encarga de convertir el conjunto de datos (test)\n",
    "# a formato CSV\n",
    "def jsonds_to_csvds_test(json_ds_path,csv_ds_path):\n",
    "    \"\"\"\n",
    "    :param json_ds_path: Ruta donde se encuentra el conjunto de datos en formato JSON.\n",
    "    :param csv_ds_path: Ruta donde almacenaremos el nuevo conjunto de datos en formato CSV.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(csv_ds_path):\n",
    "        os.mkdir(csv_ds_path)\n",
    "\n",
    "    if MPD_TEST_FILE in os.listdir(json_ds_path):\n",
    "        plstrs_fieldnames = ['pid','pos','track_uri']\n",
    "        plsinfo_fieldnames = ['pid','name','num_holdouts','num_samples',\n",
    "                              'num_tracks', 'description']\n",
    "        row_list = []\n",
    "        \n",
    "        with open(PLSTESTINFO_FILE, 'w',newline='',encoding='utf8') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=plsinfo_fieldnames,\n",
    "                                    delimiter=',',quoting=csv.QUOTE_MINIMAL)\n",
    "            writer.writeheader()\n",
    "            test_playlists = json_file_reader(os.path.join(json_ds_path,MPD_TEST_FILE))['playlists']\n",
    "            for pl in test_playlists:\n",
    "                tracks_list = pl.pop('tracks')\n",
    "                writer.writerow(pl)\n",
    "                \n",
    "                for track in tracks_list:\n",
    "                    pos = track.pop('pos')\n",
    "                    row = {'pid': pl['pid'], 'pos': pos,\n",
    "                           'track_uri' : track['track_uri']}\n",
    "                    row_list.append(row)\n",
    "        \n",
    "        plstrs_test_path = os.path.join(MPD_CSV_PATH,\"{}test.csv\".format(PLSTRS_PREFIX))\n",
    "        with open(plstrs_test_path, 'w', newline='', encoding='utf8') as csv_tracks_file:\n",
    "            writer_tracks = csv.DictWriter(csv_tracks_file, fieldnames=plstrs_fieldnames)\n",
    "            writer_tracks.writeheader()\n",
    "            for row in row_list:\n",
    "                writer_tracks.writerow(row)    \n",
    "    else:\n",
    "        print(\"ERROR: Fichero del conjunto de prueba no encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b44d713-bfae-4922-874c-fabaa3b70501",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Una vez definidas las funciones, realizamos el proceso de conversión.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "__Importante__: Este proceso puede durar entre 15 y 20.\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe7a831-0acf-4a94-b5f4-0cd42be2fa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonds_to_csvds(MPD_PATH,MPD_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb26a7b-03e2-4595-bda3-d1a09c3ce61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonds_to_csvds_test(MPD_TEST_PATH,MPD_CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab46ea7-d44e-45b7-a7ea-554f2142b8a3",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab471a15-2fcd-4496-a828-610612c7ba51",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section3\"></a>\n",
    "## <font color=\"#92002A\">3 - Modificaciones adicionales en el dataset</font>\n",
    "<br>\n",
    "\n",
    "Con el conjunto de datos ya convertido en formato *csv*, vamos a realizar una serie de cambios con los que crearemos un índice propio, distinto al de *Spotify*, para identificar los distintos elementos que conforman nuestro dataset y eliminar información innecesaria o repetida, como los prefijos de los identificadores de pistas, artistas o álbumes. También extraeremos información a otros ficheros *csv* para tener la información mejor ordenada.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "__Importante__: Este proceso puede tardar hasta 10 minutos en completarse.\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd91d796-9bcc-4a95-9607-834126c237e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_tracks = pd.read_csv(TRACKS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c36b2-e1ce-4487-9a0d-6307af380b05",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u>**Paso 1**</u><br> Creamos un conjunto de datos que contendrá la información relativa a los artistas (identificador, nombre e identificador de *Spotify* sin prefijo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f2f910b-9de6-44a6-bac5-c689aead1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists = df_tracks[['artist_name', 'artist_uri']].copy()\n",
    "df_artists.drop_duplicates(subset=['artist_uri'],inplace=True)\n",
    "df_artists.reset_index(drop=True, inplace=True)\n",
    "df_artists.index.name = 'artist_pid'\n",
    "df_artists['artist_id'] = df_artists['artist_uri'].apply(lambda x: x.split(':')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd3e967-8271-41a5-b3a2-ab55d9a84ab5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 2</strong></u><br> Creamos un conjunto de datos que contendrá la información relativa a los álbumes (identificador, nombre, artista al que pertenece e identificador de *Spotify* sin prefijo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9ae567d-07d4-4e97-b856-7fde65c7b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albums = df_tracks[['album_name', 'album_uri', 'artist_uri']].copy()\n",
    "df_albums.drop_duplicates(subset=['album_uri'],inplace=True)\n",
    "df_albums.reset_index(drop=True, inplace=True)\n",
    "df_albums.index.name = 'album_pid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a29c14-cf10-4fec-b592-bda4acc78963",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 3</strong></u><br> Eliminamos del conjunto de pistas el nombre del artista y del álbum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2fba17-a0d3-415d-af53-d4cc0d779402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks.drop(columns=['artist_name','album_name'],inplace=True)\n",
    "df_tracks.drop_duplicates(subset='track_uri',inplace=True)\n",
    "df_tracks.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f26db2-d8ac-4865-bbaa-bf1518121e1e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 4</strong></u><br> \n",
    "Sustituimos del conjunto de pistas los identificadores de *Spotify* por nuestros propios identificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a33f338-60cb-49ba-8caf-deda4c892ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks = pd.merge(df_tracks, df_artists.reset_index()[['artist_pid','artist_uri']], on=['artist_uri']) \\\n",
    "                .drop(columns=['artist_uri'])\n",
    "df_tracks = pd.merge(df_tracks, df_albums.reset_index()[['album_pid','album_uri']], on=['album_uri']) \\\n",
    "                .drop(columns=['album_uri'])\n",
    "\n",
    "df_tracks.index.name = 'track_pid'\n",
    "\n",
    "df_tracks['track_id'] = df_tracks['track_uri'].apply(lambda x: x.split(':')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5c916-d907-4b25-8ddc-c6b4ceab497a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 5</strong></u><br> \n",
    "Sustituimos del conjunto de álbumes los identificadores de *Spotify* por nuestros propios identificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "292bd8e1-4741-4adc-9461-fa27d51c933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albums = pd.merge(df_albums, df_artists.reset_index()[['artist_pid','artist_uri']], on=['artist_uri']) \\\n",
    "                .drop(columns=['artist_uri'])\n",
    "df_albums.index.name = 'album_pid'\n",
    "\n",
    "df_albums['album_id'] = df_albums['album_uri'].apply(lambda x: x.split(':')[-1])\n",
    "df_albums.drop(columns=['album_uri'], inplace = True)\n",
    "df_artists.drop(columns=['artist_uri'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887c365-4951-49bf-b4ec-db21db372db5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 6</strong></u><br> \n",
    "En el conjunto que contiene qué pistas contiene cada playlists, sustituimos los identificadores de *Spotify* para las playlists y pistas por nuestros propios identificadores y los unimos en un único fichero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43ec2c9d-d936-4a63-9568-d9a26e7b5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función empleada para leer un dataframe que ha sido almacenado\n",
    "# en varios ficheros\n",
    "def read_dataset_multifile(ds_prefix, folder=os.curdir):\n",
    "    \"\"\"\n",
    "    :param ds_prefix: Prefijo de los ficheros a leer.\n",
    "    :param folder: Directorio donde se encuentran los ficheros.\n",
    "    :return: Dataframe resultante de leer los ficheros.\n",
    "    \"\"\"\n",
    "    list_df = []\n",
    "    \n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.startswith(ds_prefix):\n",
    "            file_path = os.path.join(folder, file_name)\n",
    "            df_temp = pd.read_csv(file_path)\n",
    "            list_df.append(df_temp)\n",
    "            \n",
    "    return pd.concat(list_df, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f976062-d375-419b-9afe-f42274a45777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plstrs = read_dataset_multifile(PLSTRS_PREFIX,MPD_CSV_PATH)\n",
    "\n",
    "trackid_map_dict = df_tracks[['track_uri']].to_dict()['track_uri']\n",
    "trackid_map_dict = {v: k for k, v in trackid_map_dict.items()}\n",
    "\n",
    "df_plstrs[\"track_pid\"] = df_plstrs[\"track_uri\"].map(trackid_map_dict)\n",
    "df_plstrs.drop(columns=['track_uri'], inplace=True)\n",
    "df_tracks.drop(columns=['track_uri'], inplace=True)\n",
    "df_plstrs.sort_values(['pid', 'pos'],inplace=True)\n",
    "df_plstrs.set_index('pid',inplace=True)\n",
    "df_plstrs.index.name = 'pl_pid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1606c649-4f2a-480e-b398-42012c21b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(MPD_CSV_PATH):\n",
    "    if file_name.startswith(PLSTRS_PREFIX):\n",
    "        os.remove(os.path.join(MPD_CSV_PATH,file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa2f6e-c928-4396-a08e-63a85e12892c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 7</strong></u><br> \n",
    "Adicionalmente creamos dos nuevos conjuntos, uno que contiene que artistas aparecen en cada playlist y otro que contiene que álbumes contiene cada playlist, cada uno de ellos junto al número de apariciones de dichos elementos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b9626a-37fd-46da-8e4b-d913eb228065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apariciones de artistas en las playlits\n",
    "df_plsarts = pd.merge(df_plstrs.reset_index(), \n",
    "                      df_tracks.reset_index()[['track_pid', 'artist_pid']], on=['track_pid'])\n",
    "df_plsarts.drop(columns=['track_pid','pos'], inplace=True)\n",
    "df_plsarts.sort_values(by=['pl_pid','artist_pid'], inplace=True)\n",
    "df_plsarts = df_plsarts.groupby(['pl_pid','artist_pid']).size().to_frame(name = 'artist_count').reset_index()\n",
    "df_plsarts.set_index('pl_pid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94c51a05-749b-4484-b346-012e2b9c8e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apariciones de álbumes en las playlits\n",
    "df_plsalbums = pd.merge(df_plstrs.reset_index(), \n",
    "                        df_tracks.reset_index()[['track_pid','album_pid']], on=['track_pid'])\n",
    "df_plsalbums.drop(columns=['track_pid','pos'], inplace=True)\n",
    "df_plsalbums.sort_values(by=['pl_pid','album_pid'], inplace=True)\n",
    "df_plsalbums = df_plsalbums.groupby(['pl_pid','album_pid']).size().to_frame(name = 'album_count').reset_index()\n",
    "df_plsalbums.set_index('pl_pid',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ea087-bd21-4349-a8f4-eebfe48483d0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 8</strong></u><br> \n",
    "\n",
    "Modificamos el nombre de la columna relativa a los identificadores por el de _pl_pid_ y establecemos el tipo de datos `int` de cada columna de tipo numérico en los dataframes que contienen la información relativas a las playlists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e21da76b-419e-4089-8696-5ab1e4318e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plinfo_dtypes = {'modified_at' : int, 'num_albums': int, 'num_tracks': int, 'num_followers' : int,\n",
    "                 'num_edits': int, 'duration_ms' : int, 'num_artists': int}\n",
    "\n",
    "df_plsinfo = pd.read_csv(PLSINFO_FILE, dtype=plinfo_dtypes,index_col=0)\n",
    "df_plsinfo.index.name = 'pl_pid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4ecb6a1-3945-416a-a374-4e2287d3a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plinfotest_dtypes = {'num_holdouts' : int, 'num_samples' : int, 'num_tracks' : int}\n",
    "\n",
    "df_plsinfotest = pd.read_csv(PLSINFO_FILE, dtype=plinfotest_dtypes,index_col=0)\n",
    "df_plsinfotest.index.name = 'pl_pid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117821b1-a4be-4a7b-b7e8-ab45fbdd65dc",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "Realizadas las correspondientes modificaciones, procedemos a almacenar los archivos que conforman el conjunto de datos de playlists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf770c9d-c71e-4674-909e-fd4ce66fcb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plsarts.to_csv(PLSTARTS_FILE)\n",
    "df_artists.to_csv(ARTISTS_FILE)\n",
    "df_albums.to_csv(ALBUMS_FILE)\n",
    "df_tracks.to_csv(TRACKS_FILE)\n",
    "df_plsinfo.to_csv(PLSINFO_FILE)\n",
    "df_plsinfotest.to_csv(PLSTESTINFO_FILE)\n",
    "df_plstrs.to_csv(PLSTRS_FILE)\n",
    "df_plsalbums.to_csv(PLSALBUMS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912790b1-7234-4839-8fa9-15ce4e0b8fe0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-graduation-cap\" aria-hidden=\"true\" style=\"color:#92002A\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
