{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bba3559-4735-4b75-8be0-11a436770e58",
   "metadata": {},
   "source": [
    "<img src=\"images/header-transparent.png\" alt=\"Logo UCLM-ESII\" align=\"right\">\n",
    "\n",
    "<br><br><br><br>\n",
    "<h2><font color=\"#92002A\" size=4>Trabajo Fin de Máster</font></h2>\n",
    "\n",
    "<h1><font color=\"#6B001F\" size=5>SERENDIPITY: Servicio web para la recomendacIón de playlists a partir de otra playlist</font></h1>\n",
    "<h2><font color=\"#92002A\" size=3>Parte 1 - Preparación de datos</font></h2>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: right\">\n",
    "    <font color=\"#B20033\" size=3><strong>Autor</strong>: <em>Miguel Ángel Cantero Víllora</em></font><br>\n",
    "    <br>\n",
    "    <font color=\"#B20033\" size=3><strong>Directores</strong>: <em>José Antonio Gámez Martín</em></font><br>\n",
    "    <font color=\"#B20033\" size=3><em>Juan Ángel Aledo Sánchez</em></font><br>\n",
    "    <br>\n",
    "<font color=\"#B20033\" size=3>Máster Universitario en Ingeniería Informática</font><br>\n",
    "<font color=\"#B20033\" size=2>Escuela Superior de Ingeniería Informática | Universidad de Castilla-La Mancha</font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c7569-738d-49e9-92be-6cb9e4cde424",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#92002A\" size=5>Índice</font></h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Cambio de formato del dataset](#section2)\n",
    "* [3. Modificaciones adicionales en el dataset](#section3)\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3089c990-bceb-4403-8e71-d4402d36e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm as tqdm_nb\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e1d67d-1daa-4f09-8d08-c78aa5a545e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPD_PATH = 'MPD'\n",
    "MPD_TEST_PATH = 'MPD_TEST'\n",
    "MPD_CSV_PATH = 'MPD_CSV'\n",
    "MPD_SLICE_PREFIX = 'mpd.slice.'\n",
    "PLSTRS_PREFIX = 'mpd.playlists-tracks.'\n",
    "MPD_TEST_FILE = 'challenge_set.json'\n",
    "\n",
    "ALBUMS_FILE = os.path.join(MPD_CSV_PATH,'mpd.albums.csv')\n",
    "ARTISTS_FILE = os.path.join(MPD_CSV_PATH,'mpd.artists.csv')\n",
    "TRACKS_FILE = os.path.join(MPD_CSV_PATH,'mpd.tracks.csv')\n",
    "PLSTRS_FILE = os.path.join(MPD_CSV_PATH,'mpd.pls-tracks.csv')\n",
    "PLSTARTS_FILE = os.path.join(MPD_CSV_PATH,'mpd.pls-artists.csv')\n",
    "PLSALBUMS_FILE = os.path.join(MPD_CSV_PATH,'mpd.pls-albums.csv')\n",
    "PLSINFO_FILE = os.path.join(MPD_CSV_PATH,'mpd.playlists-info.csv')\n",
    "PLSTESTINFO_FILE = os.path.join(MPD_CSV_PATH,'mpd.playlists-info-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55a34b-4ffc-4034-b2e6-d7c217828130",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "## <font color=\"#92002A\">1 - Introducción</font>\n",
    "<br>\n",
    "\n",
    "En esta libreta, vamos a realizar una serie de cambios en el conjunto de playlists que obtuvimos en el proyecto _[Generación automática de playlist de canciones mediante técnicas de minería de datos](https://github.com/miguelangelcv/TFG-GeneracionPlaylists)_ y que emplearemos en nuestro servicio de recomendación. Lo primero que haremos será convertirlos de su formato original, *JSON*, a formato *CSV*. Este cambio lo realizamos para reducir su tamaño y poder almacenarlo en memoria, además de ser un formato compatible con librerías como _[numpy](https://numpy.org/)_ o _[pandas](https://pandas.pydata.org/)_. También realizaremos una serie de modificaciones adicionales para eliminar información innecesaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90b262-14db-42e4-b23e-da8715d2d451",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3f4157-2be9-471c-ab7b-ef86d51d1a8a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section2\"></a>\n",
    "## <font color=\"#92002A\">2 - Cambio de formato del dataset</font>\n",
    "<br>\n",
    "\n",
    "\n",
    "Este proceso generará varios ficheros *CSV* que contendrán distinta información, ya sea sobre las playlists, artistas, pistas, etc. Lo hacemos de dicha forma para que la información este mejor clasificada y sea más fácil trabajar con ella.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "__Nota__: Cuando se creó el conjunto de 1.000.000 de playlists, adicionalmente también se creó otro conjunto de 10.000 playlist, con información incompleta, como conjunto de test. Este conjunto de prueba lo incorporamos junto al conjunto inicial, que utilizaremos para realizar el entrenamiento del modelo, de tal forma que podamos evaluar los resultados que obtenemos con el modelo creado.\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Para realizar el cambio de formato del dataset, hemos creado una serie de funciones que nos ayudaran a leer y transformar los datos:\n",
    "\n",
    "* `json_file_reader`: Esta función permite leer los ficheros que componen el conjunto de datos, ya sea un archivo *JSON* o un archivo *zip* que lo contenga.\n",
    "* `jsonds_to_csvds`: Se encarga procesar todos los ficheros correspondientes al conjunto de datos que contiene las playlists y transformarlos a formato *CSV* y repartir la información en varios ficheros. \n",
    "* `jsonds_to_csvds_test`: Realiza el mismo proceso que la función anterior, pero con el conjunto de datos que emplearemos como conjunto de prueba (o test).\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a243cb9d-2ee0-439a-8556-6716588c3264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función que nos permite leer un archivo .json comprimido o sin comprimir\n",
    "# y devuelve un diccionario con su contenido\n",
    "def json_file_reader(file_path):\n",
    "    \"\"\"\n",
    "    :param file_path: Ruta del fichero a leer.\n",
    "    :return results: Diccionario con los datos leidos del fichero JSON.\n",
    "    \"\"\"\n",
    "    _ , file_extension = os.path.splitext(file_path)\n",
    "\n",
    "    # Fichero comprimido\n",
    "    if file_extension == '.zip':\n",
    "        with ZipFile(file_path,'r') as zip_file:\n",
    "            with zip_file.open(zip_file.namelist()[0]) as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "    # Fichero sin comprimir\n",
    "    elif file_extension == '.json':\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            json_data = json.load(json_file)            \n",
    "    # En caso de que sea otra extensión, devolvemos un diccionario vacío\n",
    "    else:\n",
    "        json_data = {}            \n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ddcec2e-0438-483e-8dc4-b475dd8a01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que se encarga de convertir el dataset que contiene \n",
    "# 1 millón de playlists a formato CSV\n",
    "def jsonds_to_csvds(json_ds_path,csv_ds_path):\n",
    "    \"\"\"\n",
    "    :param json_ds_path: Ruta donde se encuentra el conjunto de datos en formato JSON.\n",
    "    :param csv_ds_path: Ruta donde almacenaremos el nuevo conjunto de datos en formato CSV.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(csv_ds_path):\n",
    "        os.mkdir(csv_ds_path)    \n",
    "    \n",
    "    files = []\n",
    "    tracks_dict = defaultdict(dict)\n",
    "\n",
    "    for file in os.listdir(json_ds_path):\n",
    "        if file.startswith(MPD_SLICE_PREFIX):\n",
    "            files.append(os.path.join(json_ds_path,file))\n",
    "\n",
    "    plstrs_fieldnames = ['pid','pos','track_uri']\n",
    "    tracks_fieldnames = ['track_name', 'track_uri', 'duration_ms', 'artist_name', \n",
    "                         'artist_uri', 'album_name', 'album_uri']\n",
    "    plsinfo_fieldnames = ['pid','name','collaborative','modified_at',\n",
    "                          'num_albums','num_tracks', 'num_followers',\n",
    "                          'num_edits','duration_ms','num_artists','description']\n",
    "\n",
    "    with open(PLSINFO_FILE,'w',newline='') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=plsinfo_fieldnames,delimiter=',')\n",
    "        writer.writeheader()\n",
    "\n",
    "    print(\"[1/2] Lectura de datos en JSON:\")\n",
    "    for file in tqdm_nb(files):\n",
    "        file_name , _ = os.path.splitext(file)\n",
    "        portion = file_name.split('.')[-1]\n",
    "        csv_pltrs_file = os.path.join(csv_ds_path, f\"{PLSTRS_PREFIX}{portion}.csv\")\n",
    "        row_list = []\n",
    "\n",
    "        with open(PLSINFO_FILE,'a',encoding='utf8',newline='') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=plsinfo_fieldnames,\n",
    "                                    delimiter=',',quoting=csv.QUOTE_MINIMAL)\n",
    "            for pl in json_file_reader(file)['playlists']:\n",
    "                tracks_list = pl.pop('tracks')\n",
    "                writer.writerow(pl)\n",
    "                for track in tracks_list:\n",
    "                    pos = track.pop('pos')\n",
    "                    row = {'pid': pl['pid'], 'pos': pos,\n",
    "                           'track_uri' : track['track_uri']}\n",
    "                    row_list.append(row)\n",
    "                    tracks_dict[track['track_uri']] = track\n",
    "\n",
    "        with open(csv_pltrs_file,'w',newline='') as csv_tracks_file:\n",
    "            writer_tracks = csv.DictWriter(csv_tracks_file, fieldnames=plstrs_fieldnames)\n",
    "            writer_tracks.writeheader()\n",
    "            for row in row_list:\n",
    "                writer_tracks.writerow(row)\n",
    "    \n",
    "    print(\"[2/2] Almacenamiento de datos en CSV:\")\n",
    "    with open(TRACKS_FILE,'w',newline='', encoding='utf8') as csv_tracks_file:\n",
    "        writer_tracks = csv.DictWriter(csv_tracks_file, fieldnames=tracks_fieldnames)\n",
    "        writer_tracks.writeheader()\n",
    "        pbar = tqdm_nb(total=len(tracks_dict))\n",
    "        for track in tracks_dict.values():\n",
    "            writer_tracks.writerow(track)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da276de7-5a64-4a2c-907e-b4841140ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que se encarga de convertir el conjunto de datos (test)\n",
    "# a formato CSV\n",
    "def jsonds_to_csvds_test(json_ds_path,csv_ds_path):\n",
    "    \"\"\"\n",
    "    :param json_ds_path: Ruta donde se encuentra el conjunto de datos en formato JSON.\n",
    "    :param csv_ds_path: Ruta donde almacenaremos el nuevo conjunto de datos en formato CSV.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(csv_ds_path):\n",
    "        os.mkdir(csv_ds_path)\n",
    "\n",
    "    if MPD_TEST_FILE in os.listdir(json_ds_path):\n",
    "        plstrs_fieldnames = ['pid','pos','track_uri']\n",
    "        plsinfo_fieldnames = ['pid','name','num_holdouts','num_samples',\n",
    "                              'num_tracks', 'description']\n",
    "        row_list = []\n",
    "        \n",
    "        with open(PLSTESTINFO_FILE, 'w',newline='',encoding='utf8') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=plsinfo_fieldnames,\n",
    "                                    delimiter=',',quoting=csv.QUOTE_MINIMAL)\n",
    "            writer.writeheader()\n",
    "            test_playlists = json_file_reader(os.path.join(json_ds_path,MPD_TEST_FILE))['playlists']\n",
    "            for pl in test_playlists:\n",
    "                tracks_list = pl.pop('tracks')\n",
    "                writer.writerow(pl)\n",
    "                \n",
    "                for track in tracks_list:\n",
    "                    pos = track.pop('pos')\n",
    "                    row = {'pid': pl['pid'], 'pos': pos,\n",
    "                           'track_uri' : track['track_uri']}\n",
    "                    row_list.append(row)\n",
    "        \n",
    "        plstrs_test_path = os.path.join(MPD_CSV_PATH,\"{}test.csv\".format(PLSTRS_PREFIX))\n",
    "        with open(plstrs_test_path, 'w', newline='', encoding='utf8') as csv_tracks_file:\n",
    "            writer_tracks = csv.DictWriter(csv_tracks_file, fieldnames=plstrs_fieldnames)\n",
    "            writer_tracks.writeheader()\n",
    "            for row in row_list:\n",
    "                writer_tracks.writerow(row)    \n",
    "    else:\n",
    "        print(\"ERROR: Fichero del conjunto de prueba no encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b44d713-bfae-4922-874c-fabaa3b70501",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Una vez definidas las funciones, realizamos el proceso de conversión.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "__Importante__: Este proceso puede durar entre 15 y 20 minutos.\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe7a831-0acf-4a94-b5f4-0cd42be2fa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] Lectura de datos en JSON:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b80c25f5fd445aaded8e790541db79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Almacenamiento de datos en CSV:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a62c86434b04be4b3402669fb5c0e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2262292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jsonds_to_csvds(MPD_PATH,MPD_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb26a7b-03e2-4595-bda3-d1a09c3ce61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonds_to_csvds_test(MPD_TEST_PATH,MPD_CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab46ea7-d44e-45b7-a7ea-554f2142b8a3",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab471a15-2fcd-4496-a828-610612c7ba51",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<a id=\"section3\"></a>\n",
    "## <font color=\"#92002A\">3 - Modificaciones adicionales en el dataset</font>\n",
    "<br>\n",
    "\n",
    "Con el conjunto de datos ya convertido en formato *CSV*, vamos a realizar una serie de cambios con los que crearemos un índice propio, distinto al de *Spotify*, para identificar los distintos elementos que conforman nuestro dataset y eliminar información innecesaria o repetida, como los prefijos de los identificadores de pistas, artistas o álbumes. También extraeremos información a otros ficheros *CSV* para tenerla mejor clasificada.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<i class=\"fa fa-exclamation-circle\" aria-hidden=\"true\"></i>\n",
    "__Importante__: Este proceso puede tardar hasta 10 minutos en completarse.\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd91d796-9bcc-4a95-9607-834126c237e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_tracks = pd.read_csv(TRACKS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c36b2-e1ce-4487-9a0d-6307af380b05",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u>**Paso 1**</u><br> Creamos un conjunto de datos que contendrá la información relativa a los artistas (identificador, nombre e identificador de *Spotify* sin prefijo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f2f910b-9de6-44a6-bac5-c689aead1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists = df_tracks[['artist_name', 'artist_uri']].copy()\n",
    "df_artists.drop_duplicates(subset=['artist_uri'],inplace=True)\n",
    "df_artists.reset_index(drop=True, inplace=True)\n",
    "df_artists.index.name = 'artist_pid'\n",
    "df_artists['artist_id'] = df_artists['artist_uri'].apply(lambda x: x.split(':')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd3e967-8271-41a5-b3a2-ab55d9a84ab5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 2</strong></u><br> Creamos un conjunto de datos que contendrá la información relativa a los álbumes (identificador, nombre, artista al que pertenece e identificador de *Spotify* sin prefijo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9ae567d-07d4-4e97-b856-7fde65c7b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_albums = df_tracks[['album_name', 'album_uri', 'artist_uri']].copy()\n",
    "df_albums.drop_duplicates(subset=['album_uri'],inplace=True)\n",
    "df_albums.reset_index(drop=True, inplace=True)\n",
    "df_albums.index.name = 'album_pid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a29c14-cf10-4fec-b592-bda4acc78963",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 3</strong></u><br> Eliminamos del conjunto de pistas el nombre del artista y del álbum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb2fba17-a0d3-415d-af53-d4cc0d779402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks.drop(columns=['artist_name','album_name'],inplace=True)\n",
    "df_tracks.drop_duplicates(subset='track_uri',inplace=True)\n",
    "df_tracks.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f26db2-d8ac-4865-bbaa-bf1518121e1e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 4</strong></u><br> \n",
    "Creamos nuestros identificadores en el conjunto de pistas y eliminamos los prefijos de los identificadores de *Spotify*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a33f338-60cb-49ba-8caf-deda4c892ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks = pd.merge(df_tracks, df_albums.reset_index()[['album_pid','album_uri']], on=['album_uri'], how='left')\n",
    "df_tracks = pd.merge(df_tracks, df_artists.reset_index()[['artist_pid','artist_uri']], on=['artist_uri'], how='left')\n",
    "\n",
    "df_tracks['track_id'] = df_tracks['track_uri'].apply(lambda x: x.split(':')[-1])\n",
    "df_tracks['album_id'] = df_tracks['album_uri'].apply(lambda x: x.split(':')[-1])\n",
    "df_tracks['artist_id'] = df_tracks['artist_uri'].apply(lambda x: x.split(':')[-1])\n",
    "\n",
    "df_tracks.drop(columns=['track_uri', 'artist_uri', 'album_uri'], inplace=True)\n",
    "df_tracks.index.name = 'track_pid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5c916-d907-4b25-8ddc-c6b4ceab497a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 5</strong></u><br> \n",
    "Creamos nuestros identificadores en el conjunto de álbumes y eliminamos los prefijos de los identificadores de *Spotify*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "292bd8e1-4741-4adc-9461-fa27d51c933f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_name</th>\n",
       "      <th>artist_pid</th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>album_pid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Cookbook</td>\n",
       "      <td>0</td>\n",
       "      <td>6vV5UrXcfyQD1wu4Qo2I9K</td>\n",
       "      <td>2wIVse2owClT7go1WT98tk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In The Zone</td>\n",
       "      <td>1</td>\n",
       "      <td>0z7pVBGOD7HCIB7S8eLkLI</td>\n",
       "      <td>26dSoYclwsYLMAKD3tpOr4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dangerously In Love (Alben für die Ewigkeit)</td>\n",
       "      <td>2</td>\n",
       "      <td>25hVFAxTlDvXbx2X2QkUkE</td>\n",
       "      <td>6vWDO969PvNqNYHIOW5v0m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Justified</td>\n",
       "      <td>3</td>\n",
       "      <td>6QPkyl04rXwTGlGlcYaRoW</td>\n",
       "      <td>31TPClRtHm23RisEBtV3X7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hot Shot</td>\n",
       "      <td>4</td>\n",
       "      <td>6NmFmPX56pcLBOFMhIiKvF</td>\n",
       "      <td>5EvFsr3kj42KNv97ZEnqij</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             album_name  artist_pid  \\\n",
       "album_pid                                                             \n",
       "0                                          The Cookbook           0   \n",
       "1                                           In The Zone           1   \n",
       "2          Dangerously In Love (Alben für die Ewigkeit)           2   \n",
       "3                                             Justified           3   \n",
       "4                                              Hot Shot           4   \n",
       "\n",
       "                         album_id               artist_id  \n",
       "album_pid                                                  \n",
       "0          6vV5UrXcfyQD1wu4Qo2I9K  2wIVse2owClT7go1WT98tk  \n",
       "1          0z7pVBGOD7HCIB7S8eLkLI  26dSoYclwsYLMAKD3tpOr4  \n",
       "2          25hVFAxTlDvXbx2X2QkUkE  6vWDO969PvNqNYHIOW5v0m  \n",
       "3          6QPkyl04rXwTGlGlcYaRoW  31TPClRtHm23RisEBtV3X7  \n",
       "4          6NmFmPX56pcLBOFMhIiKvF  5EvFsr3kj42KNv97ZEnqij  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_albums = pd.merge(df_albums, df_artists.reset_index()[['artist_pid','artist_uri']], on=['artist_uri'], how='left')\n",
    "df_albums.index.name = 'album_pid'\n",
    "\n",
    "df_albums['album_id'] = df_albums['album_uri'].apply(lambda x: x.split(':')[-1])\n",
    "df_albums['artist_id'] = df_albums['artist_uri'].apply(lambda x: x.split(':')[-1])\n",
    "df_albums.drop(columns=['album_uri', 'artist_uri'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887c365-4951-49bf-b4ec-db21db372db5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 6</strong></u><br> \n",
    "En el conjunto que posee qué pistas contiene cada playlists, sustituimos los identificadores de *Spotify* para las playlists y pistas por nuestros propios identificadores y los unimos en un único fichero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43ec2c9d-d936-4a63-9568-d9a26e7b5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función empleada para leer un dataframe que ha sido almacenado\n",
    "# en varios ficheros\n",
    "def read_dataset_multifile(ds_prefix, folder=os.curdir):\n",
    "    \"\"\"\n",
    "    :param ds_prefix: Prefijo de los ficheros a leer.\n",
    "    :param folder: Directorio donde se encuentran los ficheros.\n",
    "    :return: Dataframe resultante de leer los ficheros.\n",
    "    \"\"\"\n",
    "    list_df = []\n",
    "    \n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.startswith(ds_prefix):\n",
    "            file_path = os.path.join(folder, file_name)\n",
    "            df_temp = pd.read_csv(file_path)\n",
    "            list_df.append(df_temp)\n",
    "            \n",
    "    return pd.concat(list_df, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f976062-d375-419b-9afe-f42274a45777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plstrs = read_dataset_multifile(PLSTRS_PREFIX,MPD_CSV_PATH)\n",
    "\n",
    "trackid_map_dict = df_tracks[['track_id']].to_dict()['track_id']\n",
    "trackid_map_dict = {v: k for k, v in trackid_map_dict.items()}\n",
    "\n",
    "df_plstrs['track_id'] = df_plstrs['track_uri'].apply(lambda x: x.split(':')[-1])\n",
    "df_plstrs[\"track_pid\"] = df_plstrs[\"track_id\"].map(trackid_map_dict)\n",
    "df_plstrs.drop(columns=['track_uri', 'track_id'], inplace=True)\n",
    "df_plstrs.sort_values(['pid', 'pos'],inplace=True)\n",
    "df_plstrs.set_index('pid',inplace=True)\n",
    "df_plstrs.index.name = 'pl_pid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1606c649-4f2a-480e-b398-42012c21b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in os.listdir(MPD_CSV_PATH):\n",
    "    if file_name.startswith(PLSTRS_PREFIX):\n",
    "        os.remove(os.path.join(MPD_CSV_PATH,file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa2f6e-c928-4396-a08e-63a85e12892c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 7</strong></u><br> \n",
    "Adicionalmente creamos dos nuevos conjuntos, uno que contiene qué artistas aparecen en cada playlist y otro que contiene qué álbumes contiene cada playlist, cada uno de ellos junto al número de apariciones de dichos elementos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "94c51a05-749b-4484-b346-012e2b9c8e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apariciones de álbumes en las playlits\n",
    "df_plsalbums = pd.merge(df_plstrs.reset_index(), \n",
    "                        df_tracks.reset_index()[['track_pid','album_pid']], \n",
    "                        on=['track_pid'], how='left')\n",
    "df_plsalbums.drop(columns=['track_pid','pos'], inplace=True)\n",
    "df_plsalbums.sort_values(by=['pl_pid','album_pid'], inplace=True)\n",
    "df_plsalbums = df_plsalbums.groupby(['pl_pid','album_pid']).size().to_frame(name = 'album_count').reset_index()\n",
    "df_plsalbums.set_index('pl_pid',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99b9626a-37fd-46da-8e4b-d913eb228065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apariciones de artistas en las playlits\n",
    "df_plsarts = pd.merge(df_plstrs.reset_index(), \n",
    "                      df_tracks.reset_index()[['track_pid', 'artist_pid']], \n",
    "                      on=['track_pid'], how='left')\n",
    "df_plsarts.drop(columns=['track_pid','pos'], inplace=True)\n",
    "df_plsarts.sort_values(by=['pl_pid','artist_pid'], inplace=True)\n",
    "df_plsarts = df_plsarts.groupby(['pl_pid','artist_pid']).size().to_frame(name = 'artist_count').reset_index()\n",
    "df_plsarts.set_index('pl_pid',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ea087-bd21-4349-a8f4-eebfe48483d0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<u><strong>Paso 8</strong></u><br> \n",
    "\n",
    "Modificamos el nombre de la columna relativa a los identificadores por el de _pl_pid_ y establecemos el tipo de datos `int` de cada columna de tipo numérico en los dataframes que contienen la información relativas a las playlists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e21da76b-419e-4089-8696-5ab1e4318e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plinfo_dtypes = {'modified_at' : int, 'num_albums': int, 'num_tracks': int, 'num_followers' : int,\n",
    "                 'num_edits': int, 'duration_ms' : int, 'num_artists': int}\n",
    "\n",
    "df_plsinfo = pd.read_csv(PLSINFO_FILE, dtype=plinfo_dtypes,index_col=0)\n",
    "df_plsinfo.index.name = 'pl_pid'\n",
    "df_plsinfo.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a4ecb6a1-3945-416a-a374-4e2287d3a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plinfotest_dtypes = {'num_holdouts' : int, 'num_samples' : int, 'num_tracks' : int}\n",
    "\n",
    "df_plsinfotest = pd.read_csv(PLSTESTINFO_FILE, dtype=plinfotest_dtypes,index_col=0)\n",
    "df_plsinfotest.index.name = 'pl_pid'\n",
    "df_plsinfotest.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117821b1-a4be-4a7b-b7e8-ab45fbdd65dc",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "Realizadas las correspondientes modificaciones, procedemos a almacenar los archivos que conforman el conjunto de datos de playlists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bf770c9d-c71e-4674-909e-fd4ce66fcb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks.to_csv(TRACKS_FILE)\n",
    "df_artists.to_csv(ARTISTS_FILE)\n",
    "df_albums.to_csv(ALBUMS_FILE)\n",
    "df_plsinfo.to_csv(PLSINFO_FILE)\n",
    "df_plsinfotest.to_csv(PLSTESTINFO_FILE)\n",
    "df_plstrs.to_csv(PLSTRS_FILE)\n",
    "df_plsalbums.to_csv(PLSALBUMS_FILE)\n",
    "df_plsarts.to_csv(PLSTARTS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912790b1-7234-4839-8fa9-15ce4e0b8fe0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"text-align: right\">\n",
    "<a href=\"#indice\"><font size=5><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#92002A\"></i></font></a>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-graduation-cap\" aria-hidden=\"true\" style=\"color:#92002A\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
